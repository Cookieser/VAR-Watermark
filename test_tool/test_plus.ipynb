{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch, torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import PIL.Image as PImage, PIL.ImageDraw as PImageDraw\n",
    "import torch\n",
    "import torch.nn\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from options import HiDDenConfiguration\n",
    "\n",
    "import utils\n",
    "from model.hidden import *\n",
    "from noise_layers.noiser import Noiser\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/\"\n",
    "device = torch.device('cuda:4')\n",
    "device2 = torch.device('cuda:5')\n",
    "message_length = 30\n",
    "\n",
    "batch = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hidden(options_file_path,checkpoint_file_path,device):\n",
    "    train_options, hidden_config, noise_config = utils.load_options(options_file_path)\n",
    "    noiser = Noiser(noise_config,device)\n",
    "    checkpoint = torch.load(checkpoint_file_path,weights_only=True)\n",
    "    hidden_net = Hidden(hidden_config, device, noiser, None)\n",
    "    utils.model_from_checkpoint(hidden_net, checkpoint)\n",
    "    return hidden_net.encoder_decoder.encoder, hidden_net.encoder_decoder.decoder\n",
    "\n",
    "\n",
    "\n",
    "def load_fhat(source_image_path,batch):\n",
    "    fhat = torch.load(source_image,weights_only=True)\n",
    "    print(\"Original Tensor Shape:\", fhat.shape)\n",
    "    if fhat.dim() == 3:\n",
    "        fhat.unsqueeze_(0)\n",
    "    if fhat.dim() == 4 and fhat.shape[0] > 10:\n",
    "        fhat = fhat[:batch]\n",
    "    fhat = fhat.to(device)\n",
    "    print(\"Original Tensor Shape:\", fhat.shape)\n",
    "    return fhat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_error(decoded_message,message):\n",
    "    \n",
    "    decoded_rounded = decoded_message.detach().cpu().numpy().round().clip(0, 1)\n",
    "    message_detached = message.detach().cpu().numpy()\n",
    "    bitwise_avg_err = np.sum(np.abs(decoded_rounded - message.detach().cpu().numpy()))/(fhat.shape[0] * message.shape[1])\n",
    "    return bitwise_avg_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_images = hidden_net.encoder_decoder.encoder(i,m)\n",
    "def add_watermark(image,message,hidden_encoder,device):\n",
    "    message = message.to(device)\n",
    "    image = image.to(device)\n",
    "    encoded_image = hidden_encoder(image,message)\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def get_watermark(image,hidden_decoder,device):\n",
    "    image = image.to(device)\n",
    "    decoded_message  = hidden_decoder(image)\n",
    "    return decoded_message "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_test(test_func, num_trials=100):\n",
    "    total_bitwise_avg_err = 0.0\n",
    "    for i in range(num_trials):\n",
    "        bitwise_avg_err = test_func()  \n",
    "        total_bitwise_avg_err += bitwise_avg_err\n",
    "    average_bitwise_avg_err = total_bitwise_avg_err / num_trials\n",
    "    \n",
    "    return average_bitwise_avg_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAR_model.var_use import VarTool\n",
    "var = VarTool(device = device2)\n",
    "\n",
    "source_image = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/images/epoch-original-300.pt\"\n",
    "fhat = load_fhat(source_image,8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path1 = \"/home/yw699/codes/RESULT/E1 2025.02.03--19-43-00/\"\n",
    "options_file1 = os.path.join(base_path1,\"options-and-config.pickle\")\n",
    "checkpoint_file1 =os.path.join(base_path1,\"checkpoints/E1--epoch-300.pyt\")\n",
    "hidden_encoder1,hidden_decoder1 = load_hidden(options_file1,checkpoint_file1,device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path2 = \"/home/yw699/codes/VAR-Watermark/runs/only-encoder 2025.02.07--10-58-15\"\n",
    "options_file2 = os.path.join(base_path2,\"options-and-config.pickle\")\n",
    "checkpoint_file2 =os.path.join(base_path2,\"only-encoder--epoch-88.pyt\")\n",
    "hidden_encoder2,hidden_decoder2 = load_hidden(options_file2,checkpoint_file2,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_one_time_n():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhat.shape[0],message_length))).to(device)\n",
    "    fhat_watermark = add_watermark(fhat,message,hidden_encoder1,device)\n",
    "    image_watermark = var.var_decoder(fhat_watermark)\n",
    "    assert image_watermark.shape[1:] == (3, 256, 256), f\"Expected shape (*, 3, 256, 256), but got {image_watermark.shape}\"\n",
    "    fhat_detect = var.var_encoder(image_watermark)\n",
    "    watermark = get_watermark(fhat_detect,hidden_decoder1,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "\n",
    "    return bitwise_avg_err\n",
    "test_one_time_n()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method1\n",
    "直接检测fhat，用于测试 embedding hidden 的 performance\n",
    "\n",
    "使用 fhat 训练的 hidden_encoder\n",
    "\n",
    "使用 fhat 训练的 hidden_decoder \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/\"\n",
    "options_file = os.path.join(base_path,\"options-and-config.pickle\")\n",
    "checkpoint_file =os.path.join(base_path,\"checkpoints/watermark--epoch-300.pyt\")\n",
    "hidden_encoder,hidden_decoder = load_hidden(options_file,checkpoint_file,device)\n",
    "\n",
    "source_image = os.path.join(base_path,\"images/epoch-original-300.pt\")\n",
    "fhat = load_fhat(source_image,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time1():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhat.shape[0],message_length))).to(device)\n",
    "    fhat_watermark = add_watermark(fhat,message,hidden_encoder,device)\n",
    "    watermark = get_watermark(fhat_watermark,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "    return bitwise_avg_err\n",
    "\n",
    "test_one_time1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time1, num_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method2\n",
    "\n",
    "- 使用 fhat 训练的 hidden_encoder\n",
    "\n",
    "- 使用 fhat 训练的 hidden_decoder \n",
    "\n",
    "将 fhat 使用 hidden_encoder 加上 watermark\n",
    "使用 var_decoder 生成 image\n",
    "\n",
    "检测过程：\n",
    "\n",
    "使用 var_encoder 生成 fhat\n",
    "\n",
    "然后使用 hidden_decoder 获得 watermark\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAR_model.var_use import VarTool\n",
    "var = VarTool(device = device2)\n",
    "\n",
    "source_image = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/images/epoch-original-300.pt\"\n",
    "fhat = load_fhat(source_image,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time2():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhat.shape[0],message_length))).to(device)\n",
    "    fhat_watermark = add_watermark(fhat,message,hidden_encoder,device)\n",
    "    image_watermark = var.var_decoder(fhat_watermark)\n",
    "    assert image_watermark.shape[1:] == (3, 256, 256), f\"Expected shape (*, 3, 256, 256), but got {image_watermark.shape}\"\n",
    "    fhat_detect = var.var_encoder(image_watermark)\n",
    "    watermark = get_watermark(fhat_detect,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "\n",
    "    return bitwise_avg_err\n",
    "test_one_time2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time2, num_trials=100)\n",
    "# 0.24970833256840705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3+4\n",
    "\n",
    "这个hidden_encoder可以实现从fhat嵌入到image中的识别\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/yw699/codes/VAR-Watermark/runs/E1 2025.02.03--19-43-00\"\n",
    "options_file = os.path.join(base_path,\"options-and-config.pickle\")\n",
    "checkpoint_file =os.path.join(base_path,\"checkpoints/E1--epoch-300.pyt\")\n",
    "hidden_encoder,hidden_decoder = load_hidden(options_file,checkpoint_file,device)\n",
    "\n",
    "source_image = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/images/epoch-original-300.pt\"\n",
    "fhat = load_fhat(source_image,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time3():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhat.shape[0],message_length))).to(device)\n",
    "    fhat_watermark = add_watermark(fhat,message,hidden_encoder,device)\n",
    "    watermark = get_watermark(fhat_watermark,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "    return bitwise_avg_err\n",
    "\n",
    "test_one_time3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time3, num_trials=100)\n",
    "# 0.04029166753403843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time4():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhat.shape[0],message_length))).to(device)\n",
    "    #var.save_image(var.var_decoder(fhat),\"00.png\")\n",
    "    fhat_watermark = add_watermark(fhat,message,hidden_encoder,device)\n",
    "    image_watermark = var.var_decoder(fhat_watermark)\n",
    "    assert image_watermark.shape[1:] == (3, 256, 256), f\"Expected shape (*, 3, 256, 256), but got {image_watermark.shape}\"\n",
    "    #var.save_image(image_watermark,\"4.png\")\n",
    "    fhat_detect = var.var_encoder(image_watermark)\n",
    "    watermark = get_watermark(fhat_detect,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "\n",
    "    return bitwise_avg_err\n",
    "test_one_time4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time4, num_trials=100)\n",
    "# 0.07483333380892873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 5 + 6\n",
    "\n",
    "在每个残差层使用hidden_encoder嵌入水印 + 最后在fhat上再加一遍\n",
    "\n",
    "不知道这种robustness会不会更好\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [1,3,5,7,100,2,10,8]\n",
    "fhats,hs = var.generate_form_labels(class_labels)\n",
    "\n",
    "assert torch.allclose(fhats[0], hs[0], atol=1e-6), f\"fhats[0] != hs[0]\"\n",
    "assert torch.allclose(fhats[1], fhats[0] + hs[1], atol=1e-6), f\"fhats[i+1] != fhats[i] + hs[i]\"\n",
    "assert torch.allclose(fhats[9], fhats[8] + hs[9], atol=1e-6), f\"fhats[i+1] != fhats[i] + hs[i]\"\n",
    "\n",
    "image = var.var_decoder(fhats[-1])\n",
    "\n",
    "var.save_image(image,\"best.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/\"\n",
    "options_file = os.path.join(base_path,\"options-and-config.pickle\")\n",
    "checkpoint_file =os.path.join(base_path,\"checkpoints/watermark--epoch-300.pyt\")\n",
    "hidden_encoder,hidden_decoder = load_hidden(options_file,checkpoint_file,device)\n",
    "\n",
    "# source_image = os.path.join(base_path,\"images/epoch-original-300.pt\")\n",
    "# fhat = load_fhat(source_image,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time5():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhats[-1].shape[0],message_length))).to(device)\n",
    "    hs9_watermark = add_watermark(hs[-1].clone(),message,hidden_encoder,device)\n",
    "    fhat_watermark = hs9_watermark + fhats[8].clone().to(device)\n",
    "    fhat_watermark = add_watermark(fhat_watermark,message,hidden_encoder,device)\n",
    "    watermark = get_watermark(fhat_watermark,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "    return bitwise_avg_err\n",
    "\n",
    "test_one_time5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time5, num_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time6():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhats[-1].shape[0],message_length))).to(device)\n",
    "    hs9_watermark = add_watermark(hs[-1].clone(),message,hidden_encoder,device)\n",
    "    fhat_watermark = hs9_watermark + fhats[8].clone().to(device)\n",
    "    fhat_watermark = add_watermark(fhat_watermark,message,hidden_encoder,device)\n",
    "    image_watermark = var.var_decoder(fhat_watermark)\n",
    "    assert image_watermark.shape[1:] == (3, 256, 256), f\"Expected shape (*, 3, 256, 256), but got {image_watermark.shape}\"\n",
    "    fhat_detect = var.var_encoder(image_watermark)\n",
    "    watermark = get_watermark(fhat_detect,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "\n",
    "    return bitwise_avg_err\n",
    "test_one_time6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time6, num_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/home/yw699/codes/VAR-Watermark/runs/E1 2025.02.03--19-43-00\"\n",
    "options_file = os.path.join(base_path,\"options-and-config.pickle\")\n",
    "checkpoint_file =os.path.join(base_path,\"checkpoints/E1--epoch-300.pyt\")\n",
    "hidden_encoder,hidden_decoder = load_hidden(options_file,checkpoint_file,device)\n",
    "\n",
    "source_image = \"/home/yw699/codes/RESULT/watermark 2024.12.17--15-42-23/images/epoch-original-300.pt\"\n",
    "fhat = load_fhat(source_image,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time7():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhats[-1].shape[0],message_length))).to(device)\n",
    "    hs9_watermark = add_watermark(hs[-1].clone(),message,hidden_encoder,device)\n",
    "    fhat_watermark = hs9_watermark + fhats[8].clone().to(device)\n",
    "    fhat_watermark = add_watermark(fhat_watermark,message,hidden_encoder,device)\n",
    "    watermark = get_watermark(fhat_watermark,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "    return bitwise_avg_err\n",
    "\n",
    "test_one_time7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time7, num_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time8():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhats[-1].shape[0],message_length))).to(device)\n",
    "    hs9_watermark = add_watermark(hs[-1].clone(),message,hidden_encoder,device)\n",
    "    fhat_watermark = hs9_watermark + fhats[8].clone().to(device)\n",
    "    fhat_watermark = add_watermark(fhat_watermark,message,hidden_encoder,device)\n",
    "    image_watermark = var.var_decoder(fhat_watermark)\n",
    "    assert image_watermark.shape[1:] == (3, 256, 256), f\"Expected shape (*, 3, 256, 256), but got {image_watermark.shape}\"\n",
    "    fhat_detect = var.var_encoder(image_watermark)\n",
    "    watermark = get_watermark(fhat_detect,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "\n",
    "    return bitwise_avg_err\n",
    "test_one_time8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time8, num_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_time9():\n",
    "    message = torch.Tensor(np.random.choice([0, 1], (fhats[-1].shape[0],message_length))).to(device)\n",
    "    hs9_watermark = add_watermark(hs[-1].clone(),message,hidden_encoder,device)\n",
    "    hs8_watermark = add_watermark(hs[-2].clone(),message,hidden_encoder,device)\n",
    "    fhat_watermark = hs9_watermark + hs8_watermark + fhats[7].clone().to(device)\n",
    "    fhat_watermark = add_watermark(fhat_watermark,message,hidden_encoder,device)\n",
    "    image_watermark = var.var_decoder(fhat_watermark)\n",
    "    assert image_watermark.shape[1:] == (3, 256, 256), f\"Expected shape (*, 3, 256, 256), but got {image_watermark.shape}\"\n",
    "    fhat_detect = var.var_encoder(image_watermark)\n",
    "    watermark = get_watermark(fhat_detect,hidden_decoder,device)\n",
    "    bitwise_avg_err = cal_error(watermark,message).item()\n",
    "\n",
    "    return bitwise_avg_err\n",
    "test_one_time9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_test(test_one_time9, num_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 7\n",
    "\n",
    "image-f-fhat(codebook)\n",
    "\n",
    "或者在vq之前就提前处理这个value然后加水印，分析一下codebook按理说应该是离散的几个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"Method\": [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    \"Bitwise_a\": [0.01825, 0.249708, 0.040291, 0.073333, 0.021416, 0.221000, 0.03825, 0.11],\n",
    "    \"Hidden-encoder/decoder\": [\n",
    "        \"Directly Detect\",\n",
    "        \"Use VAR Encoder/Decoder\",\n",
    "        \"Directly Detect\",\n",
    "        \"Use VAR Encoder/Decoder\",\n",
    "        \"Directly Detect\",\n",
    "        \"Use VAR Encoder/Decoder\",\n",
    "        \"Directly Detect\",\n",
    "        \"Use VAR Encoder/Decoder\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "bar_width = 0.4\n",
    "x = np.arange(len(df) // 2)  \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - bar_width / 2, df[\"Bitwise_a\"][::2], width=bar_width, color=\"blue\", label=\"Directly Detect\")\n",
    "bars2 = ax.bar(x + bar_width / 2, df[\"Bitwise_a\"][1::2], width=bar_width, color=\"orange\", label=\"Use VAR Encoder/Decoder\")\n",
    "\n",
    "\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.2f}\", ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"{df['Method'][i]} & {df['Method'][i+1]}\" for i in range(0, len(df), 2)])\n",
    "ax.set_xlabel(\"Method Pairs\")\n",
    "ax.set_ylabel(\"Bitwise_avg_err\")\n",
    "ax.set_title(\"Method vs Bitwise_avg_err\")\n",
    "\n",
    "\n",
    "ax.set_ylim(0, 0.5)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
